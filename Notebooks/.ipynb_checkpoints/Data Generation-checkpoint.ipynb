{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "N = 1000 # 1000 data points in this training set\n",
    "k = 10 # Each node in the graph will have edges to its 10 nearest neighbors\n",
    "S = 50 # need S-nn graph for soft label empirical distribution over S nearest neighbors, S >> k\n",
    "M = 4 # partition this into 4 parts\n",
    "num_points = 8 # each example has 8 points\n",
    "num_features_per_point = 2 # each point has 2 features\n",
    "\n",
    "folder = '../data/balanced_toy/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create k-NN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset of points\n",
    "points = pickle.load(open(folder + 'points.pickle', 'rb'))\n",
    "assert len(points) == N\n",
    "for point in points:\n",
    "    # every point is a 8x2 feature\n",
    "    assert point.shape[0] == num_points\n",
    "    assert point.shape[1] == num_features_per_point\n",
    "\n",
    "# Build the k-nearest neighbor graph from these nodes\n",
    "knn_graph = nx.Graph()\n",
    "for i, point in enumerate(points):\n",
    "    knn_graph.add_node(i, reading=point)\n",
    "\n",
    "# Load the pairwise distances\n",
    "distances = pickle.load(open(folder + 'distances.pickle', 'rb'))\n",
    "assert distances.shape == (N, N)\n",
    "\n",
    "# Compute the k and S nearest neighbors by sorting the distances\n",
    "S_nearest_neighbors = {}\n",
    "for i in range(N):\n",
    "    distances_for_point = list(zip(range(N), distances[i]))\n",
    "    distances_for_point.sort(key=lambda x: x[1])\n",
    "\n",
    "    # Add an edge to each of the closest neighbors, skipping the node itself\n",
    "    for j in range(1, k + 1):\n",
    "        if not knn_graph.has_edge(i, distances_for_point[j][0]):\n",
    "            knn_graph.add_edge(i, distances_for_point[j][0], weight=distances_for_point[j][0])\n",
    "\n",
    "    # Keep track of the exactly S nearest neighbors - need this for soft labels\n",
    "    S_nearest_neighbors[i] = [i]\n",
    "    for j in range(1, S):\n",
    "        S_nearest_neighbors[i].append(distances_for_point[j][0])\n",
    "\n",
    "nx.write_gpickle(knn_graph, folder + 'knn_graph.gpickle')\n",
    "pickle.dump(S_nearest_neighbors, open(folder + 'nearest_neighbors.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Graph using KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with iteration at level: 2\n",
      "done with iteration at level: 1\n",
      "done with iteration at level: 1\n"
     ]
    }
   ],
   "source": [
    "from networkx.algorithms import community\n",
    "\n",
    "# import the knn graph\n",
    "G = nx.read_gpickle(folder + 'knn_graph.gpickle')\n",
    "\n",
    "# we use a hierarchical partitioning approach to generate m balanced partitions of the graph\n",
    "# specifically, we choose m to be a power of 2 and repeatedly use Kernighan-Lin to bisect the \n",
    "# graph into 2 approximately equal parts\n",
    "def graph_partition(graph, level):\n",
    "    if level == 0:\n",
    "        return [set(graph.nodes())]\n",
    "    else:\n",
    "        part1, part2 = community.kernighan_lin_bisection(graph, weight='weight')\n",
    "        print(\"done with iteration at level: {}\".format(level))\n",
    "        return graph_partition(graph.subgraph(part1), level - 1) + graph_partition(graph.subgraph(part2), level - 1)\n",
    "\n",
    "# First, partition the knn graph formed by the training set\n",
    "num_levels = int(np.log2(M))\n",
    "assert M == 2 ** num_levels\n",
    "partition = graph_partition(G, num_levels)\n",
    "\n",
    "# check the partition was correct\n",
    "union = []\n",
    "for part in partition:\n",
    "    union += list(part)\n",
    "assert set(union) == set(G.nodes())\n",
    "\n",
    "pickle.dump(partition, open(folder + \"graph_partitions.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Graph with k-Medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the knn graph\n",
    "G = nx.read_gpickle(folder + 'knn_graph.gpickle')\n",
    "\n",
    "points = pickle.load(open(folder + 'points.pickle', 'rb'))\n",
    "distances = pickle.load(open(folder + 'distances.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_all_points(meds):\n",
    "    all_assignments = [set([]) for _ in range(M)]\n",
    "    for i, point in enumerate(points):\n",
    "        min_distance = distances[i, meds[0]]\n",
    "        assignment = 0\n",
    "        for j in range(1, M):\n",
    "            new_distance = distances[i, meds[j]]\n",
    "            if new_distance < min_distance:\n",
    "                assignment = j\n",
    "                min_distance = new_distance\n",
    "        all_assignments[assignment].add(i)\n",
    "    return all_assignments\n",
    "    \n",
    "def total_distance(med, cluster):\n",
    "    total = 0\n",
    "    for i in cluster:\n",
    "        total += distances[i, med]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "# initialize the medoid indices and partition\n",
    "medoids = np.random.choice(range(len(points)), size=M, replace=False)\n",
    "partition = assign_all_points(medoids)\n",
    "\n",
    "# keep trying to make it better\n",
    "at_least_one_changed = True\n",
    "while at_least_one_changed:\n",
    "    at_least_one_changed = False\n",
    "    \n",
    "    for i in range(len(medoids)):\n",
    "        for new_med in partition[i]:\n",
    "            if total_distance(new_med, partition[i]) < total_distance(medoids[i], partition[i]):\n",
    "                at_least_one_changed = True\n",
    "                medoids[i] = new_med\n",
    "    \n",
    "    if at_least_one_changed:\n",
    "        partition = assign_all_points(medoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(partition, open(folder + 'km_partitions.pickle', 'wb'))\n",
    "pickle.dump(medoids, open(folder + 'medoids.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
